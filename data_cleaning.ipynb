{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Finding Repeated Images\n",
    "\n",
    "This notebook identifies duplicate images in the `data/train/` folder, both within the same label folder and across different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images in: /home/nahuel/programming/ML/plant-pathology/data/train\n",
      "Label folders: ['healthy', 'rust', 'scab', 'multiple_diseases']\n"
     ]
    }
   ],
   "source": [
    "train_dir = Path('data/train')\n",
    "label_folders = ['healthy', 'rust', 'scab', 'multiple_diseases']\n",
    "\n",
    "print(f\"Looking for images in: {train_dir.absolute()}\")\n",
    "print(f\"Label folders: {label_folders}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Exact Duplicates (MD5 Hash)\n",
    "\n",
    "This method finds images that are exactly identical by computing MD5 hash of the file content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding exact duplicates...\n",
      "Found 1 groups of exact duplicates\n"
     ]
    }
   ],
   "source": [
    "def compute_md5_hash(file_path):\n",
    "    \"\"\"Compute MD5 hash of a file.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def find_exact_duplicates(train_dir, label_folders):\n",
    "    \"\"\"Find exact duplicate images using MD5 hash.\"\"\"\n",
    "    hash_to_files = defaultdict(list)\n",
    "    \n",
    "    # Compute hash for each image\n",
    "    for label in label_folders:\n",
    "        label_path = train_dir / label\n",
    "        if not label_path.exists():\n",
    "            print(f\"Warning: {label_path} does not exist\")\n",
    "            continue\n",
    "            \n",
    "        for img_file in label_path.iterdir():\n",
    "            if img_file.is_file() and img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                try:\n",
    "                    file_hash = compute_md5_hash(img_file)\n",
    "                    hash_to_files[file_hash].append((label, img_file.name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_file}: {e}\")\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = {h: files for h, files in hash_to_files.items() if len(files) > 1}\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "print(\"Finding exact duplicates...\")\n",
    "exact_duplicates = find_exact_duplicates(train_dir, label_folders)\n",
    "print(f\"Found {len(exact_duplicates)} groups of exact duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Exact Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXACT DUPLICATES FOUND\n",
      "================================================================================\n",
      "\n",
      "Group 1 (2 copies):\n",
      "  Hash: 191e6188a9a0e55c88f1a96135a28238\n",
      "  - scab: ['Train_379.jpg']\n",
      "  - multiple_diseases: ['Train_1173.jpg']\n",
      "  ⚠️  WARNING: Image appears in multiple labels: ['scab', 'multiple_diseases']\n"
     ]
    }
   ],
   "source": [
    "if exact_duplicates:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXACT DUPLICATES FOUND\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for idx, (file_hash, files) in enumerate(exact_duplicates.items(), 1):\n",
    "        print(f\"\\nGroup {idx} ({len(files)} copies):\")\n",
    "        print(f\"  Hash: {file_hash}\")\n",
    "        \n",
    "        # Group by label\n",
    "        by_label = defaultdict(list)\n",
    "        for label, filename in files:\n",
    "            by_label[label].append(filename)\n",
    "        \n",
    "        for label, filenames in by_label.items():\n",
    "            print(f\"  - {label}: {filenames}\")\n",
    "        \n",
    "        # Check if duplicate exists across different labels\n",
    "        if len(by_label) > 1:\n",
    "            print(f\"  ⚠️  WARNING: Image appears in multiple labels: {list(by_label.keys())}\")\n",
    "else:\n",
    "    print(\"No exact duplicates found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Perceptual Duplicates (Perceptual Hashing)\n",
    "\n",
    "This method finds images that are visually similar (e.g., slightly compressed, resized, or modified versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding perceptual duplicates...\n",
      "Found 5 groups of perceptual duplicates\n"
     ]
    }
   ],
   "source": [
    "import imagehash\n",
    "\n",
    "def find_perceptual_duplicates(train_dir, label_folders, hash_size=8):\n",
    "    \"\"\"Find perceptually similar images using perceptual hashing.\"\"\"\n",
    "    hash_to_files = defaultdict(list)\n",
    "    \n",
    "    # Compute perceptual hash for each image\n",
    "    for label in label_folders:\n",
    "        label_path = train_dir / label\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "            \n",
    "        for img_file in label_path.iterdir():\n",
    "            if img_file.is_file() and img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                try:\n",
    "                    img = Image.open(img_file)\n",
    "                    # Use average hash for perceptual similarity\n",
    "                    img_hash = str(imagehash.average_hash(img, hash_size=hash_size))\n",
    "                    hash_to_files[img_hash].append((label, img_file.name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_file}: {e}\")\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = {h: files for h, files in hash_to_files.items() if len(files) > 1}\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "print(\"Finding perceptual duplicates...\")\n",
    "perceptual_duplicates = find_perceptual_duplicates(train_dir, label_folders)\n",
    "print(f\"Found {len(perceptual_duplicates)} groups of perceptual duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Perceptual Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERCEPTUAL DUPLICATES FOUND\n",
      "================================================================================\n",
      "(These images are visually similar but may not be exactly identical)\n",
      "\n",
      "\n",
      "Group 1 (2 copies):\n",
      "  Hash: 1f1f01818381f1f2\n",
      "  - healthy: ['Train_1817.jpg', 'Train_174.jpg']\n",
      "\n",
      "Group 2 (2 copies):\n",
      "  Hash: 3f02010703030307\n",
      "  - healthy: ['Train_417.jpg', 'Train_1675.jpg']\n",
      "\n",
      "Group 3 (2 copies):\n",
      "  Hash: efe7a1e1e3c18111\n",
      "  - healthy: ['Train_966.jpg', 'Train_616.jpg']\n",
      "\n",
      "Group 4 (2 copies):\n",
      "  Hash: edcf87030389c1d1\n",
      "  - rust: ['Train_828.jpg', 'Train_759.jpg']\n",
      "\n",
      "Group 5 (2 copies):\n",
      "  Hash: 78dcd88000301e8f\n",
      "  - scab: ['Train_379.jpg']\n",
      "  - multiple_diseases: ['Train_1173.jpg']\n",
      "  ⚠️  WARNING: Image appears in multiple labels: ['scab', 'multiple_diseases']\n"
     ]
    }
   ],
   "source": [
    "if perceptual_duplicates:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PERCEPTUAL DUPLICATES FOUND\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"(These images are visually similar but may not be exactly identical)\\n\")\n",
    "    \n",
    "    for idx, (img_hash, files) in enumerate(perceptual_duplicates.items(), 1):\n",
    "        print(f\"\\nGroup {idx} ({len(files)} copies):\")\n",
    "        print(f\"  Hash: {img_hash}\")\n",
    "        \n",
    "        # Group by label\n",
    "        by_label = defaultdict(list)\n",
    "        for label, filename in files:\n",
    "            by_label[label].append(filename)\n",
    "        \n",
    "        for label, filenames in by_label.items():\n",
    "            print(f\"  - {label}: {filenames}\")\n",
    "        \n",
    "        # Check if duplicate exists across different labels\n",
    "        if len(by_label) > 1:\n",
    "            print(f\"  ⚠️  WARNING: Image appears in multiple labels: {list(by_label.keys())}\")\n",
    "else:\n",
    "    print(\"No perceptual duplicates found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total images per label:\n",
      "  healthy: 516\n",
      "  rust: 622\n",
      "  scab: 592\n",
      "  multiple_diseases: 91\n",
      "\n",
      "Exact duplicates: 1 groups\n",
      "Perceptual duplicates: 5 groups\n",
      "\n",
      "Duplicates across different labels:\n",
      "  Exact: 1 groups\n",
      "  Perceptual: 1 groups\n",
      "\n",
      "Duplicates within same label:\n",
      "  Exact: 0 groups\n",
      "  Perceptual: 4 groups\n"
     ]
    }
   ],
   "source": [
    "# Count total images per label\n",
    "total_images = defaultdict(int)\n",
    "for label in label_folders:\n",
    "    label_path = train_dir / label\n",
    "    if label_path.exists():\n",
    "        total_images[label] = len([f for f in label_path.iterdir() \n",
    "                                   if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTotal images per label:\")\n",
    "for label, count in total_images.items():\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "print(f\"\\nExact duplicates: {len(exact_duplicates)} groups\")\n",
    "print(f\"Perceptual duplicates: {len(perceptual_duplicates)} groups\")\n",
    "\n",
    "# Count duplicates across labels\n",
    "cross_label_exact = sum(1 for files in exact_duplicates.values() \n",
    "                        if len(set(label for label, _ in files)) > 1)\n",
    "cross_label_perceptual = sum(1 for files in perceptual_duplicates.values() \n",
    "                             if len(set(label for label, _ in files)) > 1)\n",
    "\n",
    "print(f\"\\nDuplicates across different labels:\")\n",
    "print(f\"  Exact: {cross_label_exact} groups\")\n",
    "print(f\"  Perceptual: {cross_label_perceptual} groups\")\n",
    "\n",
    "# Count duplicates within same label\n",
    "within_label_exact = len(exact_duplicates) - cross_label_exact\n",
    "within_label_perceptual = len(perceptual_duplicates) - cross_label_perceptual\n",
    "\n",
    "print(f\"\\nDuplicates within same label:\")\n",
    "print(f\"  Exact: {within_label_exact} groups\")\n",
    "print(f\"  Perceptual: {within_label_perceptual} groups\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
