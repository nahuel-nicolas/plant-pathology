{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Test Plant Pathology Model\n",
    "This notebook downloads the trained model from HuggingFace and tests it on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('data/train')\n",
    "TEST_DIR = Path('data/test')\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 260\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# HuggingFace model\n",
    "REPO_ID = 'nahuelnb/plant-pathology-efficientnetb2'\n",
    "MODEL_FILENAME = 'plant-pathology-efficientnetb2.safetensors'\n",
    "\n",
    "TEST_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "if not TEST_DIR.exists():\n",
    "    TEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'Created test directory: {TEST_DIR}')\n",
    "    \n",
    "    # Move 10% of images from each class to test set\n",
    "    for class_name in CLASS_NAMES:\n",
    "        train_class_dir = DATA_DIR / class_name\n",
    "        test_class_dir = TEST_DIR / class_name\n",
    "        test_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get all images in this class\n",
    "        all_images = list(train_class_dir.glob('*.jpg'))\n",
    "        \n",
    "        # Calculate number of test images (10%)\n",
    "        num_test = int(len(all_images) * TEST_SPLIT)\n",
    "        \n",
    "        # Randomly select images for test set\n",
    "        random.seed(42)\n",
    "        test_images = random.sample(all_images, num_test)\n",
    "        \n",
    "        # Move images from train to test\n",
    "        for img_path in test_images:\n",
    "            dest_path = test_class_dir / img_path.name\n",
    "            shutil.move(str(img_path), str(dest_path))\n",
    "        \n",
    "        print(f'{class_name}: Moved {num_test} images to test set ({len(all_images)} total)')\n",
    "    \n",
    "    print(f'\\nTest set created successfully!')\n",
    "else:\n",
    "    print(f'Test directory already exists: {TEST_DIR}')\n",
    "    # Show test set statistics\n",
    "    for class_name in CLASS_NAMES:\n",
    "        test_class_dir = TEST_DIR / class_name\n",
    "        if test_class_dir.exists():\n",
    "            num_test_images = len(list(test_class_dir.glob('*.jpg')))\n",
    "            print(f'{class_name}: {num_test_images} test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "    class_dir = TEST_DIR / class_name\n",
    "    for img_path in class_dir.glob('*.jpg'):\n",
    "        test_image_paths.append(str(img_path))\n",
    "        test_labels.append(class_idx)\n",
    "\n",
    "print(f'Test images: {len(test_image_paths)}')\n",
    "print(f'Class distribution:')\n",
    "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "    count = test_labels.count(class_idx)\n",
    "    print(f'  {class_name}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = PlantPathologyDataset(test_image_paths, test_labels, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Created test dataloader: {len(test_loader)} batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Downloading model from {REPO_ID}...')\n",
    "model_path = hf_hub_download(repo_id=REPO_ID, filename=MODEL_FILENAME)\n",
    "print(f'Model downloaded to: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PlantPathologyModel, self).__init__()\n",
    "        self.backbone = efficientnet_b2(pretrained=False)\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = PlantPathologyModel(num_classes=NUM_CLASSES)\n",
    "\n",
    "state_dict = load_file(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print('Model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "correct = sum([1 for pred, label in zip(all_preds, all_labels) if pred == label])\n",
    "accuracy = 100 * correct / len(all_labels)\n",
    "print(f'\\nTest Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Individual Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform, device):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return predicted_class, probabilities.cpu().numpy()\n",
    "\n",
    "sample_indices = random.sample(range(len(test_image_paths)), min(6, len(test_image_paths)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img_path = test_image_paths[idx]\n",
    "    true_label = test_labels[idx]\n",
    "    \n",
    "    predicted_class, probabilities = predict_image(img_path, model, test_transform, DEVICE)\n",
    "    \n",
    "    # Display image\n",
    "    image = Image.open(img_path)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Add title with prediction\n",
    "    title = f'True: {CLASS_NAMES[true_label]}\\n'\n",
    "    title += f'Pred: {CLASS_NAMES[predicted_class]} ({probabilities[predicted_class]:.2%})'\n",
    "    color = 'green' if predicted_class == true_label else 'red'\n",
    "    axes[i].set_title(title, color=color, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
